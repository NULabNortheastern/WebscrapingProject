<link rel="stylesheet" href="https://instructure-uploads.s3.amazonaws.com/account_145230000000000001/attachments/22977598/dp_app%20%25282%2529.css"><p><span style="font-weight: 400;">Information systems like Google as well as data collection, data analysis, and algorithms are </span><strong>not neutral</strong><span style="font-weight: 400;">. They can reinforce and make explicit systemic, political, and cultural biases. They are affected by input data, the way that data is presented, how the data is interpreted by machines, and more. This means we also have the ability to challenge these biases, norms, and forms of discrimination.</span></p>
<p>Watch this <a class="instructure_file_link inline_disabled" href="https://www.pbs.org/video/algorithmic-bias-and-fairness-18-4gxvyl/" target="_blank">PBS video </a>if you want to learn about the five common types of algorithmic biases that we should pay attention to and ways to reduce them.</p>
<p><iframe style="border: 0;" title="embedded content" src="https://player.pbs.org/viralplayer/3036468694/" width="512" height="332" allowfullscreen="allowfullscreen" loading="lazy"></iframe></p><script src="https://instructure-uploads.s3.amazonaws.com/account_145230000000000001/attachments/22977597/dp_app%20%25282%2529.js"></script>